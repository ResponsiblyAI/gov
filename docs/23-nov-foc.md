---
hide:
  - navigation
---

![Responsible AI, Law, Ethics & Society Logo](assets/logo.png){: style="width:300px;"}

# Operationalizing Responsible AI <br> Freedom Online Coalition (FOC) Workshop

Time: __Nobember 15, 2023__  
Place: __Hotel MANOTEL ROYAL, Rue de Lausanne 41, 1201 Genève, Switzerland__ 

## Overview

As AI becomes prevalent in many aspects of our lives, it's crucial to ensure that AI driven systems align with our societal values. A key factor in achieving this is how AI systems will be governed and regulated. Effective AI governance and regulation is challenging: open-ended legal and ethical concepts such as "fairness" or "privacy" must be transposed to concrete design specifications. This task requires “Responsible AI literacy” - an understanding of how AI systems are developed and deployed, and how design choices throughout the system life cycle affect legal, ethical and normative outcomes. This is especially crucial for policy makers and digital diplomats, who are expected to discuss, develop and agree on principles and rules in this quickly evolving space. 

During the workshop, participants will enhance their Responsible AI literacy and develop their skills to conduct an effective and critical dialogue with relevant experts.

The workshop consists of two interactive, hands-on sessions where participants engage in teamwork, designing and analyzing AI systems and discussing real-world scenarios to develop a comprehensive understanding of the interaction between AI design choices and ethical and legal implications.

The content in this workshop is designed to promote a rich discussion on the intersection of global policy, technological developments and the protection of fundamental freedoms. It aims to empower participants with tools to support them in the challenges of developing norms, principles and safeguards for Artificial Intelligence; and promoting and protecting fundamental freedoms.

This training methodology, further described [here](https://go.responsibly.ai/paper/open), was successfully implemented in multiple [settings](https://teach.responsibly.ai): academia:material-information-outline:{ title="Cornell Tech, Boston University, Princeton University, Georgetown University, Warwick University, Bocconi University, Technion, Tel Aviv University, University of Haifa. Next year also at University of California, Berkeley." }, industry:material-information-outline:{ title="At the NYC-based Runway accelerator to tech entrepreneurs." } and the government:material-information-outline:{ title="US Congress, and the Israeli Government Ministry of Innovation, Science and Technology, leading the National AI Initiative." }.

A similar workshop was delivered at the US Congress to staffers, policymakers and legal professionals in August 2023 (<http://gov.responsibly.ai/23-congress>).

This is a hands-on workshop, so participants should bring their laptop. Technical background in AI is not necessary for this workshop, it is designed specifically for policymakers.

## Agenda

| Time            | Session                                                                          |
|-----------------|----------------------------------------------------------------------------------|
| 8:45 | Arrival                                                          |
| 9:00   | First session: [Balancing trade-offs in the design of AI systems](#1-balancing-trade-offs-in-the-design-of-ai-systems) |
| 10:20        | Second session: [Deploying AI applications with foundation models & generative AI](#2-deploying-ai-applications-with-foundation-models-generative-ai) |
| 13:45 | Lunch                                                          |

## Sessions

### 1 Balancing trade-offs in the design of AI systems

To operationalize Responsible AI, one needs to translate abstract human values and principles to technical specifications, as well as to trade off between design alternatives. Every design choice carries normative implications and vice versa. 

In this session, the participants will engage in core aspects of Responsible AI through a case study pertaining to the use of AI in social services. 

The general lessons learned about the nature of trade-offs from this government case study apply to any AI system design. 

### 2 Deploying AI applications with foundation models & generative AI

The advent of recent technologies like ChatGPT has made the development of AI systems more accessible. It has also enabled software engineers without technical expertise in AI to create AI-based applications. Yet ensuring these systems perform well, exhibit robustness and adhere to human values, requires more than software engineering skills.

In this session, the participants will have a crash course in prompt engineering in order to build AI systems using foundation models and generative AI. This will serve as a scaffolding to delve into the challenges associated with evaluating and testing how systems based on foundation models  align with Responsible AI principles.

## Team

[**Niva Elkin-Koren, J.S.D.**](https://en-law.tau.ac.il/profile/elkiniva) is a Professor of Law at Tel Aviv University Faculty of Law and a Faculty Associate at the Berkman Klein Center for Internet & Society at Harvard University. She is the academic director of the Chief Justice Meir Shamgar Center for Digital Law and Innovation, a co-director of the Algorithmic Governance Lab at TAU Innovation Lab (“TIL”) and a member of the Academic Management Committee of TAU Center for Artificial Intelligence and Data Science. Her research is located at the intersection between law and information technology, focusing on values in design, intellectual property, governance by AI and governance of AI.

[**Avigdor Gal, D.Sc.**](https://agp.iem.technion.ac.il/avigal/) is the Benjamin and Florence Free Chaired Professor of Data Science and the Co-chair of the Center for Humanities & AI at the Technion - Israel Institute of Technology. He is with the Faculty of Data & Decision Sciences, where he led the design of the first engineering program in data science in Israel (and possibly the world). Gal’s research focuses on elements of data integration under uncertainty, making use of state-of-the-art machine learning and deep learning techniques to offer an improved data quality. His research is implemented, through his ties as a consultant, in multiple industries including FinTech (e.g., Pagaya). Gal has been involved in developing methods for embedding responsible AI in companies and government authorities through an education process that increases dialogue abilities between data scientists and other stakeholders (e.g., lawyers and regulators).

[**Karni Chagal-Feferkorn, Ph.D.**](https://www.shamgarlaw.sites.tau.ac.il/en/pepole/dr.-karni-chagal-feferkorn) is an Assistant Professor of Law at the Academic Center of Law & Business in Ramat-Gan, working on AI & global regulation and especially legal liability in cases where AI systems were involved in causing harm. Before that, she was a Law Postdoc fellow at the University of Ottawa.
Karni holds an LL.M. in Law & Technology from Stanford University and is a licensed attorney in New York, California and Israel. 
In addition to her academic engagement, Karni is the co-founder of a consultancy firm that advises government agencies and private sector companies on global regulation. 

[**Shlomi Hod**](https://shlomi.hod.xyz) is a computer science Ph.D. student working on Responsible AI at Boston University. Currently, he works with the Israeli Ministry of Health to release to the public the National Birth Registry using PETs (Privacy-Enhancing Technologies).
Shlomi is a member of the IEEE-USA Policy Committee.
In summer 2022, he worked as a data scientist at Twitter, where he leveraged human-in-the-loop research to improve toxicity models.
During 2020-2021, he was an Associated Researcher at the Alexander von Humboldt Institute for Internet and Society (HIIG) in Berlin.
In the past, Shlomi was the co-founder of the Israeli National Cyber Education Center. There he led the development of nationwide educational programs in computing for kids and teens. The center aims to increase the social mobility and tech participation of underrepresented groups in tech, such as women, minorities, and individuals from the suburbs of Israel. Before that, he led a data science and cybersecurity research team.

[**Amit Ashkenazi**](https://www.linkedin.com/in/amit-ashkenazi-1000b71ba/) is a law and technology expert, supporting public and private organizations on legal, policy and compliance aspects of cybersecurity, artificial intelligence, and data protection. He has extensive experience in legal policymaking in the domestic and international contexts. Amit was the legal advisor of the Israeli National Cyber Directorate (INCD) at the Prime Minister's Office between 2014 and 2022. Before INCD, Amit was Head of the Legal Department in the Israeli Law Information and Technology Authority in the Ministry of Justice (ILITA), Israel’s Data Protection Authority. In both positions Amit set up and led the legal departments and held responsibility for legal opinions, legislation, and international legal relations. Amit is a member of ISO SC-42 WG1 expert group on AI, and recently advised the Israeli Ministry of Science and Technology on the development of national artificial intelligence regulatory policy. Amit is an adjunct lecturer on cyber law and policy at the University of Tel Aviv, University of Haifa and Reichman University.

## Contact

<div class="grid cards" markdown>

__Shlomi Hod__ [shlomi@bu.edu](mailto:shlomi@bu.edu)

</div>
